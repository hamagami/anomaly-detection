{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "04_06_AE.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hamagami/anomaly-detection/blob/main/04_06_AE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LloPJKYhRrFa"
      },
      "source": [
        "# オートエンコーダによる時系列異常検知"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pwAwFbwfRrFa"
      },
      "source": [
        "### 必要なモジュールのimport"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0SCqTKMJRrFa"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Input, Dense\n",
        "from keras.models import Model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2y5NtdgERrFb"
      },
      "source": [
        "## 諸定義\r\n",
        "### セグメントの切り出し関数"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PMPq6OUNHCKa"
      },
      "source": [
        "from scipy import signal\r\n",
        "#ヒストグラム　\r\n",
        "def gethist(lst,range=(0,10),bins=25):\r\n",
        "    win= signal.hann(len(lst)) \r\n",
        "    hist, bins= np.histogram(win*lst, bins, range)\r\n",
        "    return hist, bins"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J247b98nHFBt"
      },
      "source": [
        "def segdata(lst, dim): #lst:１次元系列　dim:セグメントの幅\r\n",
        "    segs = np.empty((0,dim), float)#0×dimの空配列\r\n",
        "    hists = np.empty((0,25), float)#0×dimの空配列\r\n",
        "    for i in range(lst.size - dim + 1):#1つづつずらしながらセグメントをつくっている。最後のセグメントの開始点は lst.size-dim\r\n",
        "        hist,bins= gethist(lst[i:i+dim])\r\n",
        "        \r\n",
        "        seg=np.array(lst[i:i+dim][::-1].reshape((1,-1))) #セグメントの切り出し，時系列反転，appendのための2次ベクトル化\r\n",
        "        hist=hist.reshape((1,-1))\r\n",
        "        hists = np.append(hists,hist,axis=0)\r\n",
        "        segs = np.append(segs,seg,axis=0)\r\n",
        "\r\n",
        "    return segs, hists"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1wEN7O9sRrFb"
      },
      "source": [
        "### データ読み込み，パラメータ設定\n",
        " Keoghらの心電図のデータ  http://www.cs.ucr.edu/~eamonn/discords/qtdbsel102.txt\n",
        " Keogh, E., Lin, J. and Fu, A.: HOT SAX : Efficiently Finding the Most Unusual Time Series Subsequence, in Proceedings of the Fifth IEEE International Conference on Data Mining, ICDM 05, pp.226-233."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tj1sxa6ZRrFb"
      },
      "source": [
        "def getdata():\n",
        "  !wget \"www.dropbox.com/s/x3fmb9mxr4xkip3/qtdbsel102.txt\" #ローカルにコピーしてくる\n",
        "  LEN=3000  #分析区間\n",
        "\n",
        "  SP=0         #学習用データの開始点\n",
        "  AP=3000   #テスト用データの開始点　個のデータの場合 4250ポイント付近に異常がある\n",
        "  data = np.loadtxt(\"qtdbsel102.txt\",delimiter=\"\\t\")\n",
        "  print(\"データ数:\",data.shape[0],\"  次元数:\",data.shape[1])\n",
        "\n",
        "  #元データは3次元の時系列，3次のデータ(indexとしては2)を指定して学習/テストデータに分割\n",
        "  train_org = data[SP:SP+LEN, 2]      #学習用データとして 1～2999サンプル区間を使用\n",
        "  test_org  = data[AP:AP+LEN, 2]    #テスト用データとして3000～5999サンプルを使用\n",
        "  \n",
        "  #x軸\n",
        "  x=np.arange(SP,SP+LEN)\n",
        "\n",
        "  return x, train_org, test_org"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Au6fJ50NRrFb"
      },
      "source": [
        "x, train_org, test_org = getdata()\n",
        "\n",
        "plt.plot(x,train_org)\n",
        "plt.title(\"train\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "plt.plot(x,test_org)\n",
        "plt.title(\"test with anomaly\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2bIaQW9_RrFb"
      },
      "source": [
        "### 窓関数の設定と切り出し"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DyflNfFIRrFb"
      },
      "source": [
        "WLEN=256#セグメントのサイズ\n",
        "train_seg, train_hist= segdata(train_org, WLEN)\n",
        "test_seg, test_hist = segdata(test_org, WLEN)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ijDU56TrRrFb"
      },
      "source": [
        "## AEの学習(波形の場合）"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z2aXlCfoKpXJ"
      },
      "source": [
        "input_img = Input(shape=(WLEN,))\r\n",
        "encoded = Dense(64, activation='linear')(input_img)\r\n",
        "encoded = Dense(32, activation='relu')(encoded)\r\n",
        "encoded = Dense(16, activation='relu',name='middle_code')(encoded)\r\n",
        "\r\n",
        "decoded = Dense(32, activation='relu')(encoded)\r\n",
        "decoded = Dense(64, activation='relu')(decoded)\r\n",
        "decoded = Dense(WLEN, activation='linear',name='output_code')(decoded)\r\n",
        "\r\n",
        "autoencoder = Model(input_img, decoded)\r\n",
        "autoencoder.compile(optimizer='adam', loss='mse',metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GnGyXksKRrFc"
      },
      "source": [
        "history=autoencoder.fit(train_seg, train_seg,\n",
        "                epochs=1000,\n",
        "                batch_size=50,\n",
        "                shuffle=True,\n",
        "                verbose=1,\n",
        "                validation_split=0.1)\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('accuracy')\n",
        "plt.legend(['acc', 'val_acc'], loc='lower right')\n",
        "plt.show()\n",
        "\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss')\n",
        "plt.legend(['loss', 'val_loss'], loc='lower right')\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Brt0C2MRrFc"
      },
      "source": [
        "### 復元誤差からの異常推定"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gw27vNadRrFc"
      },
      "source": [
        "#encoded_sig = Model(input_img, encoded\n",
        "decoded_trainsig = autoencoder.predict(train_seg)\n",
        "decoded_testsig = autoencoder.predict(test_seg)\n",
        "trainloss=[]\n",
        "testloss=[]\n",
        "for i,d in enumerate(decoded_trainsig):  \n",
        "    d_trainsig = d-train_seg[i]\n",
        "    d_testsig  = decoded_testsig[i]-test_seg[i]\n",
        "    trainloss.append(np.linalg.norm(d_trainsig, ord=WLEN))\n",
        "    testloss.append(np.linalg.norm(d_testsig, ord=WLEN))\n",
        "\n",
        "plt.plot(train_org)\n",
        "plt.title(\"train AE error\")\n",
        "outlier_rows = [i for i in range(len(trainloss)) if trainloss[i]>1]\n",
        "for c in outlier_rows:\n",
        "    plt.axvspan(c, c, color = \"skyblue\")\n",
        "plt.show()\n",
        "\n",
        "plt.plot(test_org)\n",
        "plt.title(\"test AE error\")\n",
        "outlier_rows = [i for i in range(len(testloss)) if testloss[i]>1]\n",
        "for c in outlier_rows:\n",
        "    plt.axvspan(c, c, color = \"coral\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ogbV24eWJ_e8"
      },
      "source": [
        "##  AEの学習（ヒストグラム特徴の場合）"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-YONb1ijKvLa"
      },
      "source": [
        "# ヒストグラムの特徴は十分単純化されているため，AEをつかうと異常も復元できてしまうことがある。かなり低次圧縮して難しい問題にする\r\n",
        "input_img = Input(shape=(25,))\r\n",
        "encoded = Dense(32, activation='linear')(input_img)\r\n",
        "encoded = Dense(16, activation='relu')(encoded)\r\n",
        "encoded = Dense(8, activation='relu',name='middle_code')(encoded)\r\n",
        "\r\n",
        "decoded = Dense(16, activation='relu')(encoded)\r\n",
        "decoded = Dense(32, activation='relu')(decoded)\r\n",
        "decoded = Dense(25, activation='linear',name='output_code')(decoded)\r\n",
        "\r\n",
        "autoencoder = Model(input_img, decoded)\r\n",
        "autoencoder.compile(optimizer='adam', loss='mse',metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kjtf2m8sRrFc"
      },
      "source": [
        "history=autoencoder.fit(train_hist, train_hist,\r\n",
        "                epochs=150,\r\n",
        "                batch_size=50,\r\n",
        "                shuffle=True,\r\n",
        "                verbose=1,\r\n",
        "                validation_split=0.1)\r\n",
        "plt.plot(history.history['accuracy'])\r\n",
        "plt.plot(history.history['val_loss'])\r\n",
        "plt.title('model accuracy')\r\n",
        "plt.xlabel('epoch')\r\n",
        "plt.ylabel('accuracy')\r\n",
        "plt.legend(['acc', 'val_acc'], loc='lower right')\r\n",
        "plt.show()\r\n",
        "\r\n",
        "plt.plot(history.history['loss'])\r\n",
        "plt.plot(history.history['val_loss'])\r\n",
        "plt.title('model loss')\r\n",
        "plt.xlabel('epoch')\r\n",
        "plt.ylabel('loss')\r\n",
        "plt.legend(['loss', 'val_loss'], loc='lower right')\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ub8BZozKKYVy"
      },
      "source": [
        "### 復元誤差からの異常検出\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GC3w8LTkRrFc"
      },
      "source": [
        "\r\n",
        "decoded_trainsig = autoencoder.predict(train_hist)\r\n",
        "decoded_testsig = autoencoder.predict(test_hist)\r\n",
        "trainloss=[]\r\n",
        "testloss=[]\r\n",
        "for i,d in enumerate(decoded_trainsig):  \r\n",
        "    d_trainsig = d-train_hist[i]\r\n",
        "    d_testsig  = decoded_testsig[i]-test_hist[i]\r\n",
        "    trainloss.append(np.linalg.norm(d_trainsig, ord=WLEN))\r\n",
        "    testloss.append(np.linalg.norm(d_testsig, ord=WLEN))\r\n",
        "\r\n",
        "plt.plot(trainloss)\r\n",
        "plt.show()\r\n",
        "plt.plot(testloss)\r\n",
        "plt.show()\r\n",
        "plt.show()\r\n",
        "plt.plot(train_org)\r\n",
        "plt.title(\"train AE error\")\r\n",
        "outlier_rows = [i for i in range(len(trainloss)) if trainloss[i]>15]\r\n",
        "for c in outlier_rows:\r\n",
        "    plt.axvspan(c, c, color = \"skyblue\")\r\n",
        "plt.show()\r\n",
        "\r\n",
        "plt.plot(test_org)\r\n",
        "plt.title(\"test AE error\")\r\n",
        "outlier_rows = [i for i in range(len(testloss)) if testloss[i]>15]\r\n",
        "for c in outlier_rows:\r\n",
        "    plt.axvspan(c, c, color = \"coral\")\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hWbjcsG-RrFc"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}