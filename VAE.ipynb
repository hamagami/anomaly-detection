{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VAE.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMezwvzx6GCY2y/u0bQpvCO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hamagami/anomaly-detection/blob/main/VAE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ER1qKTznycGn"
      },
      "source": [
        "# VAEによる画像の異常検知\n",
        "original code from https://github.com/tarekmuallim/Anomaly-Detection-using-Variational-Autoencoders/blob/master/anomaly_detection_using_vae.py　このコードに手を加えて解説をつけている"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UZB1BJ2PyqJW"
      },
      "source": [
        "AEにくらべVAEは潜在変数を学習するため，未知のデータに対して誤りをすくなるすることができるといわれています。ここではMNISTを例に画像の異常検知を確認します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VY19lU-uy9rO"
      },
      "source": [
        "from keras.layers import Lambda, Input, Dense\n",
        "from keras.models import Model\n",
        "from keras.datasets import mnist\n",
        "from keras.losses import mse, binary_crossentropy\n",
        "from keras.utils import plot_model\n",
        "from keras import backend as K\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import argparse\n",
        "import os"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UN_efSHUzSdv"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0v2yyNr5zF2v"
      },
      "source": [
        "def sampling(args):\n",
        "    z_mean, z_log_var = args\n",
        "    batch = K.shape(z_mean)[0]\n",
        "    dim = K.int_shape(z_mean)[1]\n",
        "    epsilon = K.random_normal(shape=(batch, dim))  # by default, random_normal has mean=0 and std=1.0\n",
        "    return z_mean + K.exp(0.5* z_log_var) * epsilon"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M35Z9hEjzPW6"
      },
      "source": [
        "## MNISTデータ取得"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "omTWX3Uf1ghc"
      },
      "source": [
        "## 手書き文字１のデータを学習データとして用意し，学習用に正規化する"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z20F-sHYzb_S"
      },
      "source": [
        " # MNIST dataset\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "# get data for one digit \"1\"\n",
        "\n",
        "print(x_train.shape)\n",
        "print(y_train.shape)\n",
        "\n",
        "dig_class = 1\n",
        "\n",
        "indexes = []\n",
        "for i, j in enumerate(y_train):\n",
        "    if j == dig_class:\n",
        "        indexes.append(i)\n",
        "\n",
        "\n",
        "x_train_t = x_train[indexes]\n",
        "\n",
        "#1のみとりだす\n",
        "indexes = []\n",
        "for i, j in enumerate(y_test):\n",
        "    if j == dig_class:\n",
        "        indexes.append(i)\n",
        "\n",
        "\n",
        "x_test_t = x_test[indexes]\n",
        "\n",
        "x_train = x_train_t\n",
        "x_test = x_test_t\n",
        "print(x_train.shape)\n",
        "print(x_test.shape)\n",
        "plt.imshow(x_train[0])\n",
        "\n",
        "# reshape and normalization\n",
        "# 各画像を1次配列にして，学習とテスト用にわける\n",
        "image_size = x_train.shape[1]\n",
        "original_dim = image_size * image_size\n",
        "x_train = np.reshape(x_train, [-1, original_dim])\n",
        "x_test = np.reshape(x_test, [-1, original_dim])\n",
        "x_train = x_train.astype('float32') / 255\n",
        "x_test = x_test.astype('float32') / 255\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QoAPu5TwzoYc"
      },
      "source": [
        "###　VAEネットワークの設計"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OoIRgcrF0BPq"
      },
      "source": [
        "# network parameters and learning parameters\n",
        "input_shape = (original_dim, )\n",
        "intermediate_dim = 512\n",
        "batch_size = 128\n",
        "latent_dim = 2\n",
        "epochs = 50\n",
        "\n",
        "# encoder model\n",
        "inputs = Input(shape=input_shape, name='encoder_input')\n",
        "x = Dense(intermediate_dim, activation='relu')(inputs)\n",
        "z_mean = Dense(latent_dim, name='z_mean')(x)\n",
        "z_log_var = Dense(latent_dim, name='z_log_var')(x)\n",
        "\n",
        "# sampling\n",
        "z = Lambda(sampling, output_shape=(latent_dim,), name='z')([z_mean, z_log_var])\n",
        "\n",
        "# instantiate encoder model\n",
        "encoder = Model(inputs, [z_mean, z_log_var, z], name='encoder')\n",
        "encoder.summary()\n",
        "\n",
        "\n",
        "# decoder model\n",
        "latent_inputs = Input(shape=(latent_dim,), name='z_sampling')\n",
        "x = Dense(intermediate_dim, activation='relu')(latent_inputs)\n",
        "outputs = Dense(original_dim, activation='sigmoid')(x)\n",
        "\n",
        "# instantiate decoder model\n",
        "decoder = Model(latent_inputs, outputs, name='decoder')\n",
        "decoder.summary()\n",
        "\n",
        "# instantiate VAE model\n",
        "outputs = decoder(encoder(inputs)[2])\n",
        "vae = Model(inputs, outputs, name='vae')\n",
        "vae.summary()\n",
        "\n",
        "# VAE loss\n",
        "# reconstruction_loss = mse(inputs, outputs)\n",
        "reconstruction_loss = binary_crossentropy(inputs, outputs)\n",
        "reconstruction_loss *= original_dim\n",
        "kl_loss = 1 + z_log_var - K.square(z_mean) - K.exp(z_log_var)\n",
        "kl_loss = K.sum(kl_loss, axis=-1)\n",
        "kl_loss *= -0.5\n",
        "vae_loss = K.mean(reconstruction_loss + kl_loss)\n",
        "# vae_loss = K.mean(reconstruction_loss)\n",
        "\n",
        "# vae.compile(optimizer='adam', loss=vae_loss)\n",
        "vae.add_loss(vae_loss)\n",
        "vae.compile(optimizer='adam')\n",
        "vae.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "elq8Ao613Idu"
      },
      "source": [
        "## 学習\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p2-d0_Te0LEc"
      },
      "source": [
        "# Learning\n",
        "# epochs = 50\n",
        "history = vae.fit(x_train, epochs=epochs, batch_size=batch_size, validation_data=(x_test, None))\n",
        "\n",
        "vae.save_weights('vae_mnist.h5')\n",
        "\n",
        "# plot loss history\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs = range(len(loss))\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "snLTb9QD3XlZ"
      },
      "source": [
        "### テストデータをいれたときの潜在変数の分布を確認"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UeyCDbDV0XYy"
      },
      "source": [
        "# Visualization of latent space\n",
        "z_mean, _, _ = encoder.predict(x_test, batch_size=batch_size)\n",
        "plt.scatter(z_mean[:, 0], z_mean[:, 1])\n",
        "plt.xlabel(\"z[0]\")\n",
        "plt.ylabel(\"z[1]\")\n",
        "plt.title('Test Data Latent Space')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XNAmpzIo3mhs"
      },
      "source": [
        "### 学習データをいれたときの潜在変数を確認"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "87q4mipT0b-5"
      },
      "source": [
        "# Visualization of latent space\n",
        "z_mean, _, _ = encoder.predict(x_train, batch_size=batch_size)\n",
        "plt.scatter(z_mean[:, 0], z_mean[:, 1])\n",
        "plt.xlabel(\"z[0]\")\n",
        "plt.ylabel(\"z[1]\")\n",
        "plt.title('Train Data Latent Space')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i1SgaoPk4HyR"
      },
      "source": [
        "## 再度MNISTからデータを読みこみ，すべてを正規化"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6NZtrY910nmy"
      },
      "source": [
        "# MNIST dataset\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "image_size = x_train.shape[1]\n",
        "original_dim = image_size * image_size\n",
        "x_train = np.reshape(x_train, [-1, original_dim])\n",
        "x_test = np.reshape(x_test, [-1, original_dim])\n",
        "x_train = x_train.astype('float32') / 255\n",
        "x_test = x_test.astype('float32') / 255"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Md6RkBul4Naw"
      },
      "source": [
        "### すべてのデータに対して，学習済VAEをいれて内部変数を確認"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IB-7ehcn0sLe"
      },
      "source": [
        "\"\"\"# Visualization of Latent Space\n",
        "When we supply the whole data to the trained VAE, we can see that result is separable\n",
        "the anomaly digits (digits which is not \"one\") are outside the distribution of normal latent space.\n",
        "\"\"\"\n",
        "\n",
        "# Visualization of latent space\n",
        "z_mean,z_log_var, _ = encoder.predict(x_test, batch_size=batch_size)\n",
        "\n",
        "plt.scatter(z_mean[:, 0], z_mean[:, 1], c=y_test)\n",
        "plt.colorbar()\n",
        "plt.set_cmap('tab10')\n",
        "plt.xlabel(\"z[0]\")\n",
        "plt.ylabel(\"z[1]\")\n",
        "plt.title('Latent Space for All Data')\n",
        "plt.show()\n",
        "\n",
        "# Visualization of latent space\n",
        "\n",
        "plt.scatter(z_log_var[:, 0], z_log_var[:, 1], c=y_test)\n",
        "plt.colorbar()\n",
        "plt.set_cmap('tab10')\n",
        "plt.xlabel(\"z_log_var[0]\")\n",
        "plt.ylabel(\"z_log_var[1]\")\n",
        "plt.title('Latent Space for All Data')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bd_LD9AX41dS"
      },
      "source": [
        "### 入力に対する復元画像を確認，１に対しては当然１がでてくるが，１でない入力についても，すべて１に近い画像がでてくるはず（復元誤差が大きい）"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X5GHNbF4y_aA"
      },
      "source": [
        "# test reconstruction for one digit\n",
        "\n",
        "i = 14\n",
        "\n",
        "digit_size = 28\n",
        "\n",
        "\n",
        "digit = x_train[i].reshape(digit_size, digit_size)\n",
        "\n",
        "figure = digit\n",
        "plt.figure(figsize=(5, 5))\n",
        "plt.imshow(figure, cmap='gray')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n",
        "z_sample = np.array(z_mean)\n",
        "x_decoded = decoder.predict(z_sample)\n",
        "digit = x_decoded[i].reshape(digit_size, digit_size)\n",
        "\n",
        "\n",
        "figure = digit\n",
        "plt.figure(figsize=(5, 5))\n",
        "plt.imshow(figure, cmap='gray')\n",
        "plt.show()\n",
        "\n",
        "# test reconstruction\n",
        "n = 20\n",
        "digit_size = 28\n",
        "figure = np.zeros((digit_size * 2, digit_size * n))\n",
        "grid_x = np.linspace(0, n, n)\n",
        "\n",
        "\n",
        "for j, xi in enumerate(grid_x):\n",
        "        z_sample = np.array(z_mean)\n",
        "        x_decoded = decoder.predict(z_sample)\n",
        "        digit = x_train[j].reshape(digit_size, digit_size)\n",
        "        figure[0 * digit_size: (0 + 1) * digit_size,\n",
        "               j * digit_size: (j + 1) * digit_size] = digit\n",
        "        digit = x_decoded[j].reshape(digit_size, digit_size)\n",
        "        figure[1 * digit_size: (1 + 1) * digit_size,\n",
        "               j * digit_size: (j + 1) * digit_size] = digit\n",
        "\n",
        "plt.figure(figsize=(n, n))\n",
        "\n",
        "plt.imshow(figure, cmap='gray')\n",
        "plt.show()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t_712n9XxBWs"
      },
      "source": [],
      "execution_count": 11,
      "outputs": []
    }
  ]
}