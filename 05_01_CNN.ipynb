{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "05_01_CNN.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hamagami/anomaly-detection/blob/main/05_01_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5U8fubAHfENi"
      },
      "source": [
        "# Simple anomaly detection based on image features extracted by VGG16 network.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1pdoh_r0fQtl"
      },
      "source": [
        "Prepare images of various guitars, and images that are not similar to guitars. Can you find an image that is not a guitar?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DcbS1Jh9axNy"
      },
      "source": [
        "# Download the guitar images. It'll take a while.\n",
        "!wget https://dl.dropbox.com/s/dmjzsrqa9s22joi/imgs.zip\n",
        "!unzip -d . imgs.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4jtyg7Easoq"
      },
      "source": [
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras import models, optimizers, layers\n",
        "from keras.preprocessing.image import array_to_img, img_to_array, load_img, ImageDataGenerator\n",
        "#from keras.applications.resnet50 import preprocess_input\n",
        "from keras.applications.vgg16 import preprocess_input\n",
        "from sklearn.svm import OneClassSVM\n",
        "\n",
        "import glob  \n",
        "from PIL import Image \n",
        "import numpy as np  \n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn import preprocessing\n",
        "import matplotlib.image as mpimg\n",
        "import random"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3srDnOB4fjcI"
      },
      "source": [
        "## Adjust the size of the image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68hvg1Xkasor"
      },
      "source": [
        "def expand2square(pil_img, background_color):\n",
        "    width, height = pil_img.size\n",
        "    if width == height:\n",
        "        return pil_img\n",
        "    elif width > height:\n",
        "        result = Image.new(pil_img.mode, (width, width), background_color)\n",
        "        result.paste(pil_img, (0, (width - height) // 2))\n",
        "        return result\n",
        "    else:\n",
        "        result = Image.new(pil_img.mode, (height, height), background_color)\n",
        "        result.paste(pil_img, ((height - width) // 2, 0))\n",
        "        return result"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cV0B7SxofsXU"
      },
      "source": [
        "## Bring up the generic learned network VGG16."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "DaZO4u_7asor"
      },
      "source": [
        "model = VGG16(weights='imagenet', include_top=False, pooling=\"avg\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y4QikqDhfw44"
      },
      "source": [
        "## Prepare a function to extract features from an image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7XF8xf-casor"
      },
      "source": [
        "def feature_extraction(model, img_path, image_size=224):\n",
        "    im=load_img(f)\n",
        "    img = expand2square(im, (128, 128, 128)).resize((image_size, image_size))\n",
        "    x = img_to_array(img)\n",
        "    x = np.expand_dims(x, axis=0)  # add a dimention of samples\n",
        "    x = preprocess_input(x)  # RGB 2 BGR and zero-centering by mean pixel based on the position of channels\n",
        "\n",
        "    feat = model.predict(x)  # Get image features\n",
        "    feat = feat.flatten()  # Convert 3-dimentional matrix to (1, n) array\n",
        "\n",
        "    return feat"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B3AcSdy8f4WM"
      },
      "source": [
        "## Feature Extraction of Guitar Image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4SniJYbugBph"
      },
      "source": [
        "\n",
        "files = glob.glob(\"./imgs/guitar/*\") \n",
        "# test\n",
        "for f in random.sample(files, 3):\n",
        "  print(f)\n",
        "  ret= feature_extraction(model, f, 224)\n",
        "  plt.imshow(mpimg.imread(f))\n",
        "  plt.plot(ret*10)\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y24iX90wasor"
      },
      "source": [
        "# Perform feature extraction of all guitar images. It takes quite some time.\n",
        "data=[]\n",
        "for f in files:\n",
        "        print(f)\n",
        "        ret= feature_extraction(model, f, 224)\n",
        "        data.append(ret)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ASym68LUasot"
      },
      "source": [
        "# Let's use PCA to look at the approximate distribution.\n",
        "data = np.array(data)\n",
        "pca = PCA(n_components=2)\n",
        "pdata =np.array(pca.fit_transform(data))\n",
        "plt.scatter(pdata.T[0],pdata.T[1])\n",
        "plt.title(\"feafure map PCA 2D\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hJ7WSsptasou"
      },
      "source": [
        "# oneclassSVM\n",
        "mmscaler = preprocessing.MinMaxScaler() \n",
        "mmscaler.fit(data)  \n",
        "sdata=mmscaler.transform(data)\n",
        "\n",
        "#decision value\n",
        "ocsvm = OneClassSVM(nu=0.001, kernel=\"rbf\", gamma='auto')\n",
        "ocsvm.fit(sdata)\n",
        "y_pred = ocsvm.decision_function(sdata).ravel()\n",
        "plt.plot(y_pred)\n",
        "plt.title(\"decision value (train data)\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E-z4HWBojh2e"
      },
      "source": [
        "### Let's also look for features in images that are not guitars.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o2BKVw26asou"
      },
      "source": [
        "adata=[]\n",
        "files = glob.glob(\"./imgs/others/*\")   \n",
        "\n",
        "for f in np.sort(files):\n",
        "        print(f)\n",
        "        ret= feature_extraction(model, f, 224)\n",
        "        plt.imshow(mpimg.imread(f))\n",
        "        plt.plot(ret*10)\n",
        "        plt.show()\n",
        "        adata.append(ret)\n",
        "adata = np.array(adata)\n",
        "sadata=mmscaler.transform(adata)\n",
        "apred=ocsvm.predict(sadata)\n",
        "a_pca_data =np.array(pca.fit_transform(adata))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-G7h-f3KkLyD"
      },
      "source": [
        "## Let's look at the difference between a non-guitar image and a guitar image on the PCA plane.It is not well represented on the two-dimensional plane, but we can see that it is still out of the guitar cluster.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Prztmawtasou"
      },
      "source": [
        "plt.scatter(pdata.T[0],pdata.T[1])\n",
        "plt.scatter(a_pca_data.T[0][0],a_pca_data.T[1][0],label=\"hyotan\",marker=\"D\")\n",
        "plt.scatter(a_pca_data.T[0][1],a_pca_data.T[1][1],label=\"neko\",marker=\"D\")\n",
        "plt.scatter(a_pca_data.T[0][2],a_pca_data.T[1][2],label=\"chell\",marker=\"D\")\n",
        "plt.scatter(a_pca_data.T[0][3],a_pca_data.T[1][3],label=\"ukurere\",marker=\"D\")\n",
        "plt.scatter(a_pca_data.T[0][4],a_pca_data.T[1][4],label=\"elec\",marker=\"D\")\n",
        "plt.scatter(a_pca_data.T[0][5],a_pca_data.T[1][5],label=\"violin\",marker=\"D\")\n",
        "plt.scatter(a_pca_data.T[0][6],a_pca_data.T[1][6],label=\"ilust\",marker=\"D\")\n",
        "plt.scatter(a_pca_data.T[0][7],a_pca_data.T[1][7],label=\"piano\",marker=\"D\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-EmwWlp_asou"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n_8i918-asou"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}