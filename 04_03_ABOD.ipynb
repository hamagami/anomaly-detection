{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "04_03_ABOD.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hamagami/anomaly-detection/blob/main/04_03_ABOD.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w5DLNYMaqIkD"
      },
      "source": [
        "# ABOD\n",
        "角度に基づく密度推定によって外れを調べる方法です。\n",
        "KNNやLOCは次元が増えると距離の意味がなくなってくるのに対し，角度に基づくABODは高次元でも妥当な外れを見つけることが可能です。一方で計算量が多いのでいくつかの高速化の試みがあります。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3npZ77UBqIkJ"
      },
      "source": [
        "import numpy as np\n",
        "import itertools\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Io8QSFMb9Im5"
      },
      "source": [
        "FastABOD\n",
        "http://ni4muraano.hatenablog.com/entry/2017/11/14/193000"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XXLgEhJ99DMo"
      },
      "source": [
        "class FastABOD:\n",
        "    def __init__(self, n_neighbors):\n",
        "        self.n_neighbors = n_neighbors\n",
        "\n",
        "    def fit_predict(self, X, contamination=0.1):\n",
        "        # 各点のk最近傍を求める\n",
        "        k_nearest = NearestNeighbors(n_neighbors=self.n_neighbors).fit(X)\n",
        "        distances, indices = k_nearest.kneighbors(X)\n",
        "        # k最近傍との角度を求めるための組み合わせ計算\n",
        "        numbers = [i + 1 for i in range(distances.shape[1] - 1)]\n",
        "        combs = list(itertools.combinations(numbers, 2))\n",
        "        # ABOFを求める\n",
        "        abofs = []\n",
        "        for i in range(len(X)):\n",
        "            x = X[indices[i]]\n",
        "            abof = self._compute_abof(x, combs)\n",
        "            abofs.append(abof)\n",
        "        # ABOFスコア下位N%を異常と見なす\n",
        "        ordered_abofs = np.argsort(abofs)\n",
        "        anomaly_indices = ordered_abofs[:int(len(abofs)*contamination + 0.5)]\n",
        "        # scikit-learnに倣って正常を1、異常を-1として返す\n",
        "        prediction = np.ones((len(abofs)), dtype=np.int32)\n",
        "        prediction[anomaly_indices] = -1\n",
        "        return prediction\n",
        "\n",
        "    def _compute_abof(self, x, combs):\n",
        "        numerator1 = 0\n",
        "        numerator2 = 0\n",
        "        denominator1 = 0\n",
        "        for comb in combs:\n",
        "            AB = x[comb[0]] - x[0]\n",
        "            AC = x[comb[1]] - x[0]\n",
        "            AB_norm = np.linalg.norm(AB)\n",
        "            AC_norm = np.linalg.norm(AC)\n",
        "            a = 1 / (AB_norm * AC_norm)\n",
        "            b = np.dot(AB, AC) / ((AB_norm ** 2) * (AC_norm ** 2))\n",
        "            numerator1 += a * (b ** 2)\n",
        "            denominator1 += a\n",
        "            numerator2 += a * b\n",
        "        denominator2 = denominator1\n",
        "        return numerator1 / denominator1 - (numerator2 / denominator2) ** 2"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zC4OCqfZ9m0a"
      },
      "source": [
        "データ分布例"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lEE6CX3o9hEg"
      },
      "source": [
        "def makedata1():#単一分布の例\n",
        "  dnum=1000\n",
        "  mean = np.array([0, 0]) # 平均\n",
        "  cov = np.array([[1, 0.7],[0.7, 2]]) # 共分散行列\n",
        "  x, y = np.random.multivariate_normal(mean, cov, dnum).T #多変量正規分布に従う乱数を生成\n",
        "  data=np.array([x,y]).T\n",
        "  return data"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lEsrmX609ick"
      },
      "source": [
        "def makedata2(): #複数分布の例\n",
        "  dnum=100\n",
        "\n",
        "  mean1 = np.array([0, -2]) # 平均を指定。\n",
        "  cov1 = np.array([[1, 0.7],[0.7, 2]]) # 共分散行列を指定。\n",
        "  x1, y1 = np.random.multivariate_normal(mean1, cov1, dnum).T\n",
        "\n",
        "  mean2 = np.array([4, 4]) # 平均を指定。\n",
        "  cov2 = np.array([[1, -0.3],[0.7, 0.4]]) # 共分散行列を指定。\n",
        "  x2, y2 = np.random.multivariate_normal(mean2, cov2, dnum).T\n",
        "\n",
        "  mean3 = np.array([-3, 5]) # 平均を指定。\n",
        "  cov3 = np.array([[0.8, -0.1],[1.0, 2]]) # 共分散行列を指定。\n",
        "  x3, y3 = np.random.multivariate_normal(mean3, cov3, dnum).T\n",
        "\n",
        "  mean=np.array([mean1,mean2,mean3])\n",
        "  cov =np.array([cov1,cov2,cov3])\n",
        "  x = np.hstack([x1, x2, x3])\n",
        "  y = np.hstack([y1,y2,y3])\n",
        "  data=np.array([x,y]).T\n",
        "\n",
        "  return data"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H_D0l2cuqIkK"
      },
      "source": [
        "\n",
        "# Generate train data\n",
        "#X = 0.3 * np.random.randn(100, 2)\n",
        "# Generate some abnormal novel observations\n",
        "#X_outliers = np.random.uniform(low=-4, high=4, size=(20, 2))\n",
        "#X = np.r_[X + 2, X - 2, X_outliers]\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GGKP6aJDqIkK"
      },
      "source": [
        "Xs=[makedata1(),makedata2()]\n",
        "\n",
        "for X in Xs:\n",
        "  clf = FastABOD(n_neighbors=10)\n",
        "  #contamination = 0.05 # 全体の5%を異常と定義\n",
        "  y_pred = clf.fit_predict(X, contamination=0.05)\n",
        "  predicted_outlier_index = np.where(y_pred == -1)\n",
        "  predicted_outlier = X[predicted_outlier_index]\n",
        "  plt.plot(X.T[0],X.T[1],\".\")\n",
        "  plt.plot(predicted_outlier.T[0],predicted_outlier.T[1],\"o\")\n",
        "  plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "505wR0PWqIkL"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pEJNQpvDqIkM"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}